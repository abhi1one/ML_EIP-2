{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 4 Assignment DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d1d4702-f485-42b5-b140-f857e5a8d08f"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128 #128 - original batch size\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a95d0574-e62f-45e2-c021-d71a1e8192ca"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "#print (img_height, img_width, channel)\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 15s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 32  # original is 12 thinking of making iteration with 64\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Fourth_Block = add_denseblock(Third_Transition, num_filter, dropout_rate)\n",
        "Fourth_Transition = add_transition(Fourth_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Fourth_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12274
        },
        "outputId": "aa8edbbf-1357-4c51-877c-974ef81ec768"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 32)   864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 32, 32, 32)   128         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 32, 32, 32)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 16)   4608        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 32, 32, 16)   0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 32, 32, 48)   0           conv2d_131[0][0]                 \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 32, 32, 48)   192         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 32, 32, 48)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 16)   6912        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 32, 32, 16)   0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 32, 32, 64)   0           concatenate_121[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 32, 32, 64)   256         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 32, 32, 64)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 32, 32, 16)   9216        activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 32, 32, 16)   0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 32, 32, 80)   0           concatenate_122[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 32, 32, 80)   320         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 32, 32, 80)   0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 32, 32, 16)   11520       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 32, 32, 16)   0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 32, 32, 96)   0           concatenate_123[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 32, 32, 96)   384         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 32, 32, 96)   0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 32, 32, 16)   13824       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 32, 32, 16)   0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 32, 32, 112)  0           concatenate_124[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 32, 32, 112)  448         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 32, 32, 112)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 32, 32, 16)   16128       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 32, 32, 16)   0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 32, 32, 128)  0           concatenate_125[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 32, 32, 128)  512         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 32, 32, 128)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 32, 32, 16)   18432       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 32, 32, 16)   0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 32, 32, 144)  0           concatenate_126[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 32, 32, 144)  576         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 144)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 32, 32, 16)   20736       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 32, 32, 16)   0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 32, 32, 160)  0           concatenate_127[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 32, 32, 160)  640         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 32, 32, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 32, 32, 16)   23040       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 32, 32, 16)   0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 32, 32, 176)  0           concatenate_128[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 32, 32, 176)  704         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 176)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 32, 32, 16)   25344       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 32, 32, 16)   0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 32, 32, 192)  0           concatenate_129[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 32, 32, 192)  768         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 32, 32, 192)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 32, 32, 16)   27648       activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 32, 32, 16)   0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 32, 32, 208)  0           concatenate_130[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 208)  832         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 208)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 32, 32, 16)   29952       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 32, 32, 16)   0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 32, 32, 224)  0           concatenate_131[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 32, 32, 224)  896         concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 32, 32, 224)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 32, 32, 16)   3584        activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 32, 32, 16)   0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 16)   0           dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 16, 16, 16)   64          average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 16, 16, 16)   0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 16, 16, 16)   2304        activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 16, 16, 16)   0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 16, 16, 32)   0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 16, 16, 32)   128         concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 16, 16, 32)   0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 16, 16, 16)   4608        activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 16, 16, 16)   0           conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 16, 16, 48)   0           concatenate_133[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 16, 16, 48)   192         concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 16, 16, 48)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 16, 16, 16)   6912        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 16, 16, 16)   0           conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 16, 16, 64)   0           concatenate_134[0][0]            \n",
            "                                                                 dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 16, 16, 64)   256         concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 16, 16, 64)   0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 16, 16, 16)   9216        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 16, 16, 16)   0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 16, 16, 80)   0           concatenate_135[0][0]            \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 16, 16, 80)   320         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 16, 16, 80)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 16, 16, 16)   11520       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 16, 16, 16)   0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 16, 16, 96)   0           concatenate_136[0][0]            \n",
            "                                                                 dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 16, 16, 96)   384         concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 16, 16, 96)   0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 16, 16, 16)   13824       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 16, 16, 16)   0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 16, 16, 112)  0           concatenate_137[0][0]            \n",
            "                                                                 dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 16, 16, 112)  448         concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 16, 16, 112)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 16, 16, 16)   16128       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 16, 16, 16)   0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 16, 16, 128)  0           concatenate_138[0][0]            \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 128)  512         concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 128)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 16, 16, 16)   18432       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 16, 16, 16)   0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 16, 16, 144)  0           concatenate_139[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 16, 16, 144)  576         concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 144)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 16, 16, 16)   20736       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 16, 16, 16)   0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 16, 16, 160)  0           concatenate_140[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 16, 16, 160)  640         concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 16, 16, 160)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 16, 16, 16)   23040       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 16, 16, 16)   0           conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 16, 16, 176)  0           concatenate_141[0][0]            \n",
            "                                                                 dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 16, 16, 176)  704         concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 16, 16, 176)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 16, 16, 16)   25344       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_152 (Dropout)           (None, 16, 16, 16)   0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 16, 16, 192)  0           concatenate_142[0][0]            \n",
            "                                                                 dropout_152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 16, 16, 192)  768         concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 16, 16, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 16, 16, 16)   27648       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_153 (Dropout)           (None, 16, 16, 16)   0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 16, 16, 208)  0           concatenate_143[0][0]            \n",
            "                                                                 dropout_153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 16, 16, 208)  832         concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 16, 16, 208)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 16, 16, 16)   3328        activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_154 (Dropout)           (None, 16, 16, 16)   0           conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 8, 8, 16)     0           dropout_154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 8, 8, 16)     64          average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 8, 8, 16)     0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 8, 8, 16)     2304        activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_155 (Dropout)           (None, 8, 8, 16)     0           conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_145 (Concatenate)   (None, 8, 8, 32)     0           average_pooling2d_12[0][0]       \n",
            "                                                                 dropout_155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 8, 8, 32)     128         concatenate_145[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 8, 8, 32)     0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 8, 8, 16)     4608        activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_156 (Dropout)           (None, 8, 8, 16)     0           conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_146 (Concatenate)   (None, 8, 8, 48)     0           concatenate_145[0][0]            \n",
            "                                                                 dropout_156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 8, 8, 48)     192         concatenate_146[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 8, 8, 48)     0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 8, 8, 16)     6912        activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_157 (Dropout)           (None, 8, 8, 16)     0           conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_147 (Concatenate)   (None, 8, 8, 64)     0           concatenate_146[0][0]            \n",
            "                                                                 dropout_157[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 8, 8, 64)     256         concatenate_147[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 8, 8, 64)     0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 8, 8, 16)     9216        activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_158 (Dropout)           (None, 8, 8, 16)     0           conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_148 (Concatenate)   (None, 8, 8, 80)     0           concatenate_147[0][0]            \n",
            "                                                                 dropout_158[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 8, 8, 80)     320         concatenate_148[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 8, 8, 80)     0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 8, 8, 16)     11520       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_159 (Dropout)           (None, 8, 8, 16)     0           conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_149 (Concatenate)   (None, 8, 8, 96)     0           concatenate_148[0][0]            \n",
            "                                                                 dropout_159[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 8, 8, 96)     384         concatenate_149[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 8, 8, 96)     0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 8, 8, 16)     13824       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_160 (Dropout)           (None, 8, 8, 16)     0           conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_150 (Concatenate)   (None, 8, 8, 112)    0           concatenate_149[0][0]            \n",
            "                                                                 dropout_160[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 8, 8, 112)    448         concatenate_150[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 8, 8, 112)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 8, 8, 16)     16128       activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_161 (Dropout)           (None, 8, 8, 16)     0           conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_151 (Concatenate)   (None, 8, 8, 128)    0           concatenate_150[0][0]            \n",
            "                                                                 dropout_161[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 8, 8, 128)    512         concatenate_151[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 8, 8, 128)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 16)     18432       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_162 (Dropout)           (None, 8, 8, 16)     0           conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_152 (Concatenate)   (None, 8, 8, 144)    0           concatenate_151[0][0]            \n",
            "                                                                 dropout_162[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 144)    576         concatenate_152[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 144)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 8, 8, 16)     20736       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_163 (Dropout)           (None, 8, 8, 16)     0           conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_153 (Concatenate)   (None, 8, 8, 160)    0           concatenate_152[0][0]            \n",
            "                                                                 dropout_163[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 8, 8, 160)    640         concatenate_153[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 8, 8, 160)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 8, 8, 16)     23040       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_164 (Dropout)           (None, 8, 8, 16)     0           conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_154 (Concatenate)   (None, 8, 8, 176)    0           concatenate_153[0][0]            \n",
            "                                                                 dropout_164[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 8, 8, 176)    704         concatenate_154[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 8, 8, 176)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 8, 8, 16)     25344       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_165 (Dropout)           (None, 8, 8, 16)     0           conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_155 (Concatenate)   (None, 8, 8, 192)    0           concatenate_154[0][0]            \n",
            "                                                                 dropout_165[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 8, 8, 192)    768         concatenate_155[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 16)     27648       activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_166 (Dropout)           (None, 8, 8, 16)     0           conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_156 (Concatenate)   (None, 8, 8, 208)    0           concatenate_155[0][0]            \n",
            "                                                                 dropout_166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 208)    832         concatenate_156[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 208)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 16)     3328        activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_167 (Dropout)           (None, 8, 8, 16)     0           conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 4, 4, 16)     0           dropout_167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 4, 4, 16)     64          average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 4, 4, 16)     0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 4, 4, 16)     2304        activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_168 (Dropout)           (None, 4, 4, 16)     0           conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_157 (Concatenate)   (None, 4, 4, 32)     0           average_pooling2d_13[0][0]       \n",
            "                                                                 dropout_168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 4, 4, 32)     128         concatenate_157[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 4, 4, 32)     0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 4, 4, 16)     4608        activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_169 (Dropout)           (None, 4, 4, 16)     0           conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_158 (Concatenate)   (None, 4, 4, 48)     0           concatenate_157[0][0]            \n",
            "                                                                 dropout_169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 4, 4, 48)     192         concatenate_158[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 4, 4, 48)     0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 4, 4, 16)     6912        activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_170 (Dropout)           (None, 4, 4, 16)     0           conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_159 (Concatenate)   (None, 4, 4, 64)     0           concatenate_158[0][0]            \n",
            "                                                                 dropout_170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 4, 4, 64)     256         concatenate_159[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 4, 4, 64)     0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 4, 4, 16)     9216        activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_171 (Dropout)           (None, 4, 4, 16)     0           conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_160 (Concatenate)   (None, 4, 4, 80)     0           concatenate_159[0][0]            \n",
            "                                                                 dropout_171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 4, 4, 80)     320         concatenate_160[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 4, 4, 80)     0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 4, 4, 16)     11520       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_172 (Dropout)           (None, 4, 4, 16)     0           conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_161 (Concatenate)   (None, 4, 4, 96)     0           concatenate_160[0][0]            \n",
            "                                                                 dropout_172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 4, 4, 96)     384         concatenate_161[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 4, 4, 96)     0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 4, 4, 16)     13824       activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_173 (Dropout)           (None, 4, 4, 16)     0           conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_162 (Concatenate)   (None, 4, 4, 112)    0           concatenate_161[0][0]            \n",
            "                                                                 dropout_173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 4, 4, 112)    448         concatenate_162[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 4, 4, 112)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 4, 4, 16)     16128       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_174 (Dropout)           (None, 4, 4, 16)     0           conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_163 (Concatenate)   (None, 4, 4, 128)    0           concatenate_162[0][0]            \n",
            "                                                                 dropout_174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 4, 4, 128)    512         concatenate_163[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 4, 4, 128)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 4, 4, 16)     18432       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_175 (Dropout)           (None, 4, 4, 16)     0           conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_164 (Concatenate)   (None, 4, 4, 144)    0           concatenate_163[0][0]            \n",
            "                                                                 dropout_175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 4, 4, 144)    576         concatenate_164[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 4, 4, 144)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 4, 4, 16)     20736       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_176 (Dropout)           (None, 4, 4, 16)     0           conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_165 (Concatenate)   (None, 4, 4, 160)    0           concatenate_164[0][0]            \n",
            "                                                                 dropout_176[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 4, 4, 160)    640         concatenate_165[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 4, 4, 160)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 4, 4, 16)     23040       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_177 (Dropout)           (None, 4, 4, 16)     0           conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_166 (Concatenate)   (None, 4, 4, 176)    0           concatenate_165[0][0]            \n",
            "                                                                 dropout_177[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 4, 4, 176)    704         concatenate_166[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 4, 4, 176)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 4, 4, 16)     25344       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_178 (Dropout)           (None, 4, 4, 16)     0           conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_167 (Concatenate)   (None, 4, 4, 192)    0           concatenate_166[0][0]            \n",
            "                                                                 dropout_178[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 4, 4, 192)    768         concatenate_167[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 4, 4, 192)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 4, 4, 16)     27648       activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_179 (Dropout)           (None, 4, 4, 16)     0           conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_168 (Concatenate)   (None, 4, 4, 208)    0           concatenate_167[0][0]            \n",
            "                                                                 dropout_179[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 4, 4, 208)    832         concatenate_168[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 4, 4, 208)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 4, 4, 16)     3328        activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_180 (Dropout)           (None, 4, 4, 16)     0           conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 2, 2, 16)     0           dropout_180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 2, 2, 16)     64          average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 2, 2, 16)     0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 2, 2, 16)     2304        activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_181 (Dropout)           (None, 2, 2, 16)     0           conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_169 (Concatenate)   (None, 2, 2, 32)     0           average_pooling2d_14[0][0]       \n",
            "                                                                 dropout_181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 2, 2, 32)     128         concatenate_169[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 2, 2, 32)     0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 2, 2, 16)     4608        activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_182 (Dropout)           (None, 2, 2, 16)     0           conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_170 (Concatenate)   (None, 2, 2, 48)     0           concatenate_169[0][0]            \n",
            "                                                                 dropout_182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 2, 2, 48)     192         concatenate_170[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 2, 2, 48)     0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 2, 2, 16)     6912        activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_183 (Dropout)           (None, 2, 2, 16)     0           conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_171 (Concatenate)   (None, 2, 2, 64)     0           concatenate_170[0][0]            \n",
            "                                                                 dropout_183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 2, 2, 64)     256         concatenate_171[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 2, 2, 64)     0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 2, 2, 16)     9216        activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_184 (Dropout)           (None, 2, 2, 16)     0           conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_172 (Concatenate)   (None, 2, 2, 80)     0           concatenate_171[0][0]            \n",
            "                                                                 dropout_184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 2, 2, 80)     320         concatenate_172[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 2, 2, 80)     0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 2, 2, 16)     11520       activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_185 (Dropout)           (None, 2, 2, 16)     0           conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_173 (Concatenate)   (None, 2, 2, 96)     0           concatenate_172[0][0]            \n",
            "                                                                 dropout_185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 2, 2, 96)     384         concatenate_173[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 2, 2, 96)     0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 2, 2, 16)     13824       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_186 (Dropout)           (None, 2, 2, 16)     0           conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_174 (Concatenate)   (None, 2, 2, 112)    0           concatenate_173[0][0]            \n",
            "                                                                 dropout_186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 2, 2, 112)    448         concatenate_174[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 2, 2, 112)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 2, 2, 16)     16128       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_187 (Dropout)           (None, 2, 2, 16)     0           conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_175 (Concatenate)   (None, 2, 2, 128)    0           concatenate_174[0][0]            \n",
            "                                                                 dropout_187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 2, 2, 128)    512         concatenate_175[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 2, 2, 128)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 2, 2, 16)     18432       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_188 (Dropout)           (None, 2, 2, 16)     0           conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_176 (Concatenate)   (None, 2, 2, 144)    0           concatenate_175[0][0]            \n",
            "                                                                 dropout_188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 2, 2, 144)    576         concatenate_176[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 2, 2, 144)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 2, 2, 16)     20736       activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_189 (Dropout)           (None, 2, 2, 16)     0           conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_177 (Concatenate)   (None, 2, 2, 160)    0           concatenate_176[0][0]            \n",
            "                                                                 dropout_189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 2, 2, 160)    640         concatenate_177[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 2, 2, 160)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 2, 2, 16)     23040       activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_190 (Dropout)           (None, 2, 2, 16)     0           conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_178 (Concatenate)   (None, 2, 2, 176)    0           concatenate_177[0][0]            \n",
            "                                                                 dropout_190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 2, 2, 176)    704         concatenate_178[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 2, 2, 176)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 2, 2, 16)     25344       activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_191 (Dropout)           (None, 2, 2, 16)     0           conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_179 (Concatenate)   (None, 2, 2, 192)    0           concatenate_178[0][0]            \n",
            "                                                                 dropout_191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 2, 2, 192)    768         concatenate_179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 2, 2, 192)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 2, 2, 16)     27648       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_192 (Dropout)           (None, 2, 2, 16)     0           conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_180 (Concatenate)   (None, 2, 2, 208)    0           concatenate_179[0][0]            \n",
            "                                                                 dropout_192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 2, 2, 208)    832         concatenate_180[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 2, 2, 208)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 1, 1, 208)    0           activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 208)          0           average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           2090        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 972,682\n",
            "Trainable params: 957,706\n",
            "Non-trainable params: 14,976\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rF3jNDdfvx-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        },
        "outputId": "1e0c1dc6-9287-4473-f076-525fc89bedd2"
      },
      "cell_type": "code",
      "source": [
        "# Adding Image Augmentation\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.1, zoom_range=0.1)\n",
        "\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
        "test_generator = test_gen.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=60000//batch_size, epochs=epochs, validation_data=test_generator, validation_steps=10000//batch_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "468/468 [==============================] - 154s 328ms/step - loss: 1.1500 - acc: 0.5872 - val_loss: 1.7372 - val_acc: 0.5232\n",
            "Epoch 2/50\n",
            "468/468 [==============================] - 157s 336ms/step - loss: 1.1485 - acc: 0.5884 - val_loss: 1.2152 - val_acc: 0.6041\n",
            "Epoch 3/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.1287 - acc: 0.5934 - val_loss: 1.3959 - val_acc: 0.5721\n",
            "Epoch 4/50\n",
            "468/468 [==============================] - 160s 342ms/step - loss: 1.1236 - acc: 0.5957 - val_loss: 1.2954 - val_acc: 0.5894\n",
            "Epoch 5/50\n",
            "468/468 [==============================] - 156s 333ms/step - loss: 1.1208 - acc: 0.5982 - val_loss: 1.1613 - val_acc: 0.6137\n",
            "Epoch 6/50\n",
            "468/468 [==============================] - 158s 339ms/step - loss: 1.1125 - acc: 0.6002 - val_loss: 1.2121 - val_acc: 0.6042\n",
            "Epoch 7/50\n",
            "468/468 [==============================] - 162s 345ms/step - loss: 1.1041 - acc: 0.6038 - val_loss: 1.3217 - val_acc: 0.5584\n",
            "Epoch 8/50\n",
            "468/468 [==============================] - 156s 333ms/step - loss: 1.1016 - acc: 0.6056 - val_loss: 1.3155 - val_acc: 0.5958\n",
            "Epoch 9/50\n",
            "468/468 [==============================] - 157s 335ms/step - loss: 1.0952 - acc: 0.6100 - val_loss: 1.1595 - val_acc: 0.6141\n",
            "Epoch 10/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 1.0850 - acc: 0.6117 - val_loss: 1.3060 - val_acc: 0.5803\n",
            "Epoch 11/50\n",
            "468/468 [==============================] - 159s 340ms/step - loss: 1.0790 - acc: 0.6152 - val_loss: 1.2594 - val_acc: 0.6034\n",
            "Epoch 12/50\n",
            "468/468 [==============================] - 162s 345ms/step - loss: 1.0783 - acc: 0.6132 - val_loss: 1.2345 - val_acc: 0.6074\n",
            "Epoch 13/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.0691 - acc: 0.6165 - val_loss: 1.2996 - val_acc: 0.5925\n",
            "Epoch 14/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 1.0682 - acc: 0.6187 - val_loss: 1.2076 - val_acc: 0.6139\n",
            "Epoch 15/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 1.0647 - acc: 0.6182 - val_loss: 1.3617 - val_acc: 0.5690\n",
            "Epoch 16/50\n",
            "468/468 [==============================] - 161s 343ms/step - loss: 1.0526 - acc: 0.6242 - val_loss: 1.2626 - val_acc: 0.6076\n",
            "Epoch 17/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.0535 - acc: 0.6224 - val_loss: 1.1287 - val_acc: 0.6323\n",
            "Epoch 18/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.0460 - acc: 0.6273 - val_loss: 1.2120 - val_acc: 0.6159\n",
            "Epoch 19/50\n",
            "468/468 [==============================] - 156s 334ms/step - loss: 1.0419 - acc: 0.6270 - val_loss: 1.2159 - val_acc: 0.6018\n",
            "Epoch 20/50\n",
            "468/468 [==============================] - 157s 335ms/step - loss: 1.0417 - acc: 0.6299 - val_loss: 1.2595 - val_acc: 0.6042\n",
            "Epoch 21/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.0337 - acc: 0.6324 - val_loss: 1.2950 - val_acc: 0.5968\n",
            "Epoch 22/50\n",
            "468/468 [==============================] - 160s 342ms/step - loss: 1.0306 - acc: 0.6313 - val_loss: 1.3155 - val_acc: 0.5973\n",
            "Epoch 23/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 1.0279 - acc: 0.6336 - val_loss: 1.3578 - val_acc: 0.5795\n",
            "Epoch 24/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.0288 - acc: 0.6319 - val_loss: 1.2176 - val_acc: 0.6164\n",
            "Epoch 25/50\n",
            "468/468 [==============================] - 160s 342ms/step - loss: 1.0167 - acc: 0.6364 - val_loss: 1.2642 - val_acc: 0.5929\n",
            "Epoch 26/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 1.0131 - acc: 0.6387 - val_loss: 1.1425 - val_acc: 0.6349\n",
            "Epoch 27/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 1.0062 - acc: 0.6410 - val_loss: 1.3014 - val_acc: 0.5998\n",
            "Epoch 28/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 1.0030 - acc: 0.6427 - val_loss: 1.2468 - val_acc: 0.6100\n",
            "Epoch 29/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 1.0061 - acc: 0.6419 - val_loss: 1.1748 - val_acc: 0.6289\n",
            "Epoch 30/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9980 - acc: 0.6444 - val_loss: 1.4071 - val_acc: 0.5843\n",
            "Epoch 31/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9968 - acc: 0.6440 - val_loss: 1.2550 - val_acc: 0.6211\n",
            "Epoch 32/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9918 - acc: 0.6469 - val_loss: 1.1039 - val_acc: 0.6467\n",
            "Epoch 33/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9861 - acc: 0.6492 - val_loss: 1.4501 - val_acc: 0.5687\n",
            "Epoch 34/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9816 - acc: 0.6506 - val_loss: 1.2531 - val_acc: 0.6122\n",
            "Epoch 35/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9830 - acc: 0.6499 - val_loss: 1.1670 - val_acc: 0.6275\n",
            "Epoch 36/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9774 - acc: 0.6521 - val_loss: 1.2272 - val_acc: 0.6219\n",
            "Epoch 37/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9691 - acc: 0.6536 - val_loss: 1.2111 - val_acc: 0.6280\n",
            "Epoch 38/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9746 - acc: 0.6561 - val_loss: 1.1328 - val_acc: 0.6407\n",
            "Epoch 39/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9659 - acc: 0.6571 - val_loss: 1.1649 - val_acc: 0.6361\n",
            "Epoch 40/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9662 - acc: 0.6558 - val_loss: 1.2781 - val_acc: 0.6087\n",
            "Epoch 41/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9636 - acc: 0.6565 - val_loss: 1.1836 - val_acc: 0.6292\n",
            "Epoch 42/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9618 - acc: 0.6585 - val_loss: 1.3665 - val_acc: 0.6073\n",
            "Epoch 43/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9553 - acc: 0.6620 - val_loss: 1.2099 - val_acc: 0.6274\n",
            "Epoch 44/50\n",
            "468/468 [==============================] - 159s 340ms/step - loss: 0.9513 - acc: 0.6618 - val_loss: 1.3212 - val_acc: 0.6192\n",
            "Epoch 45/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9478 - acc: 0.6628 - val_loss: 1.2753 - val_acc: 0.6214\n",
            "Epoch 46/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9474 - acc: 0.6638 - val_loss: 1.4793 - val_acc: 0.5764\n",
            "Epoch 47/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9427 - acc: 0.6639 - val_loss: 1.1716 - val_acc: 0.6391\n",
            "Epoch 48/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.9423 - acc: 0.6639 - val_loss: 1.3244 - val_acc: 0.6152\n",
            "Epoch 49/50\n",
            "468/468 [==============================] - 154s 328ms/step - loss: 0.9406 - acc: 0.6666 - val_loss: 1.3716 - val_acc: 0.6045\n",
            "Epoch 50/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.9364 - acc: 0.6682 - val_loss: 1.1854 - val_acc: 0.6394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26fa64ecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "eabe5842-173b-45bd-f8dc-45edb5d8e915"
      },
      "cell_type": "code",
      "source": [
        "# Model fit implimentation that came with original code\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.8559 - acc: 0.6984 - val_loss: 1.4505 - val_acc: 0.5998\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8531 - acc: 0.6982 - val_loss: 1.0591 - val_acc: 0.6661\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8538 - acc: 0.6973 - val_loss: 1.0366 - val_acc: 0.6673\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8405 - acc: 0.7038 - val_loss: 0.9587 - val_acc: 0.6941\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8416 - acc: 0.7023 - val_loss: 1.0804 - val_acc: 0.6618\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8385 - acc: 0.7042 - val_loss: 1.1149 - val_acc: 0.6551\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8340 - acc: 0.7053 - val_loss: 0.9983 - val_acc: 0.6764\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.8339 - acc: 0.7057 - val_loss: 1.0189 - val_acc: 0.6751\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8281 - acc: 0.7053 - val_loss: 1.0824 - val_acc: 0.6500\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8278 - acc: 0.7079 - val_loss: 0.9954 - val_acc: 0.6839\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8273 - acc: 0.7067 - val_loss: 1.1103 - val_acc: 0.6616\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8227 - acc: 0.7089 - val_loss: 1.0611 - val_acc: 0.6658\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8201 - acc: 0.7095 - val_loss: 0.9910 - val_acc: 0.6828\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8163 - acc: 0.7111 - val_loss: 1.0043 - val_acc: 0.6847\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8178 - acc: 0.7118 - val_loss: 0.9817 - val_acc: 0.6795\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8163 - acc: 0.7113 - val_loss: 1.0681 - val_acc: 0.6813\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8126 - acc: 0.7129 - val_loss: 0.9782 - val_acc: 0.6919\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8099 - acc: 0.7142 - val_loss: 1.1016 - val_acc: 0.6639\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8059 - acc: 0.7157 - val_loss: 1.0363 - val_acc: 0.6768\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8008 - acc: 0.7189 - val_loss: 0.9638 - val_acc: 0.6993\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8012 - acc: 0.7176 - val_loss: 1.1852 - val_acc: 0.6606\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7991 - acc: 0.7199 - val_loss: 1.1930 - val_acc: 0.6438\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7967 - acc: 0.7186 - val_loss: 1.0901 - val_acc: 0.6665\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7948 - acc: 0.7204 - val_loss: 1.0210 - val_acc: 0.6866\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7944 - acc: 0.7211 - val_loss: 1.0864 - val_acc: 0.6722\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7920 - acc: 0.7219 - val_loss: 0.9214 - val_acc: 0.7010\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7930 - acc: 0.7212 - val_loss: 1.1654 - val_acc: 0.6459\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7849 - acc: 0.7247 - val_loss: 0.8619 - val_acc: 0.7206\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7865 - acc: 0.7237 - val_loss: 0.9750 - val_acc: 0.6879\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7824 - acc: 0.7259 - val_loss: 0.9707 - val_acc: 0.6942\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7795 - acc: 0.7270 - val_loss: 1.0078 - val_acc: 0.6924\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7803 - acc: 0.7259 - val_loss: 1.1148 - val_acc: 0.6772\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7781 - acc: 0.7269 - val_loss: 0.9229 - val_acc: 0.7063\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7753 - acc: 0.7292 - val_loss: 0.9968 - val_acc: 0.6839\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7747 - acc: 0.7279 - val_loss: 0.9203 - val_acc: 0.7060\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7719 - acc: 0.7291 - val_loss: 0.9954 - val_acc: 0.6941\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7714 - acc: 0.7304 - val_loss: 0.9411 - val_acc: 0.7065\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7655 - acc: 0.7316 - val_loss: 0.9644 - val_acc: 0.7027\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7606 - acc: 0.7342 - val_loss: 0.9297 - val_acc: 0.7149\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7656 - acc: 0.7303 - val_loss: 0.9887 - val_acc: 0.6894\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7652 - acc: 0.7323 - val_loss: 1.0945 - val_acc: 0.6790\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7585 - acc: 0.7317 - val_loss: 0.9917 - val_acc: 0.6829\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7553 - acc: 0.7368 - val_loss: 1.0693 - val_acc: 0.6718\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7565 - acc: 0.7352 - val_loss: 0.8935 - val_acc: 0.7201\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7565 - acc: 0.7336 - val_loss: 0.9272 - val_acc: 0.7145\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7510 - acc: 0.7381 - val_loss: 0.9617 - val_acc: 0.7048\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7525 - acc: 0.7372 - val_loss: 0.8887 - val_acc: 0.7192\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7472 - acc: 0.7393 - val_loss: 1.1092 - val_acc: 0.6801\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 0.7437 - acc: 0.7393 - val_loss: 1.1321 - val_acc: 0.6638\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.7433 - acc: 0.7403 - val_loss: 1.2462 - val_acc: 0.6427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26fa73de48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "wksM_-92nkOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        },
        "outputId": "54a0ff07-5303-4725-bce3-41400d96fc09"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch=60000//batch_size, epochs=epochs, validation_data=test_generator, validation_steps=10000//batch_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.8562 - acc: 0.7004 - val_loss: 1.4974 - val_acc: 0.6159\n",
            "Epoch 2/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.8470 - acc: 0.7021 - val_loss: 1.4259 - val_acc: 0.6275\n",
            "Epoch 3/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8358 - acc: 0.7060 - val_loss: 1.5239 - val_acc: 0.6173\n",
            "Epoch 4/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8369 - acc: 0.7061 - val_loss: 1.2322 - val_acc: 0.6549\n",
            "Epoch 5/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8372 - acc: 0.7074 - val_loss: 1.2788 - val_acc: 0.6551\n",
            "Epoch 6/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.8359 - acc: 0.7067 - val_loss: 1.1340 - val_acc: 0.6691\n",
            "Epoch 7/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8328 - acc: 0.7079 - val_loss: 1.3382 - val_acc: 0.6420\n",
            "Epoch 8/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8273 - acc: 0.7103 - val_loss: 1.1899 - val_acc: 0.6640\n",
            "Epoch 9/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8267 - acc: 0.7093 - val_loss: 1.0174 - val_acc: 0.6909\n",
            "Epoch 10/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8250 - acc: 0.7115 - val_loss: 1.2614 - val_acc: 0.6589\n",
            "Epoch 11/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8249 - acc: 0.7101 - val_loss: 1.4107 - val_acc: 0.6236\n",
            "Epoch 12/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8227 - acc: 0.7115 - val_loss: 1.0336 - val_acc: 0.6944\n",
            "Epoch 13/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8184 - acc: 0.7147 - val_loss: 1.1414 - val_acc: 0.6653\n",
            "Epoch 14/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8197 - acc: 0.7140 - val_loss: 1.0647 - val_acc: 0.6879\n",
            "Epoch 15/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8166 - acc: 0.7138 - val_loss: 1.2075 - val_acc: 0.6556\n",
            "Epoch 16/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8148 - acc: 0.7138 - val_loss: 1.3933 - val_acc: 0.6281\n",
            "Epoch 17/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8139 - acc: 0.7149 - val_loss: 1.0292 - val_acc: 0.6970\n",
            "Epoch 18/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.8060 - acc: 0.7167 - val_loss: 1.2971 - val_acc: 0.6488\n",
            "Epoch 19/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8150 - acc: 0.7155 - val_loss: 1.4255 - val_acc: 0.6250\n",
            "Epoch 20/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.8080 - acc: 0.7183 - val_loss: 1.0200 - val_acc: 0.6950\n",
            "Epoch 21/50\n",
            "468/468 [==============================] - 152s 325ms/step - loss: 0.8002 - acc: 0.7202 - val_loss: 1.1004 - val_acc: 0.6798\n",
            "Epoch 22/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.8011 - acc: 0.7190 - val_loss: 0.9940 - val_acc: 0.7051\n",
            "Epoch 23/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.7998 - acc: 0.7195 - val_loss: 1.0167 - val_acc: 0.6915\n",
            "Epoch 24/50\n",
            "468/468 [==============================] - 152s 325ms/step - loss: 0.7977 - acc: 0.7207 - val_loss: 1.1064 - val_acc: 0.6829\n",
            "Epoch 25/50\n",
            "468/468 [==============================] - 152s 325ms/step - loss: 0.7991 - acc: 0.7193 - val_loss: 1.0635 - val_acc: 0.6870\n",
            "Epoch 26/50\n",
            "468/468 [==============================] - 152s 324ms/step - loss: 0.7985 - acc: 0.7205 - val_loss: 1.0129 - val_acc: 0.6976\n",
            "Epoch 27/50\n",
            "468/468 [==============================] - 152s 324ms/step - loss: 0.7926 - acc: 0.7235 - val_loss: 1.1135 - val_acc: 0.6779\n",
            "Epoch 28/50\n",
            "468/468 [==============================] - 151s 323ms/step - loss: 0.7864 - acc: 0.7256 - val_loss: 1.1359 - val_acc: 0.6685\n",
            "Epoch 29/50\n",
            "468/468 [==============================] - 152s 325ms/step - loss: 0.7949 - acc: 0.7232 - val_loss: 1.1420 - val_acc: 0.6767\n",
            "Epoch 30/50\n",
            "468/468 [==============================] - 153s 326ms/step - loss: 0.7868 - acc: 0.7254 - val_loss: 1.3197 - val_acc: 0.6371\n",
            "Epoch 31/50\n",
            "468/468 [==============================] - 157s 336ms/step - loss: 0.7830 - acc: 0.7261 - val_loss: 0.8611 - val_acc: 0.7269\n",
            "Epoch 32/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.7838 - acc: 0.7249 - val_loss: 0.9516 - val_acc: 0.7116\n",
            "Epoch 33/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.7915 - acc: 0.7233 - val_loss: 1.4015 - val_acc: 0.6353\n",
            "Epoch 34/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.7789 - acc: 0.7291 - val_loss: 1.5360 - val_acc: 0.6173\n",
            "Epoch 35/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.7818 - acc: 0.7290 - val_loss: 1.0241 - val_acc: 0.7028\n",
            "Epoch 36/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.7796 - acc: 0.7275 - val_loss: 1.1380 - val_acc: 0.6764\n",
            "Epoch 37/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.7740 - acc: 0.7301 - val_loss: 1.0668 - val_acc: 0.6908\n",
            "Epoch 38/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.7747 - acc: 0.7293 - val_loss: 1.3189 - val_acc: 0.6450\n",
            "Epoch 39/50\n",
            "468/468 [==============================] - 154s 329ms/step - loss: 0.7744 - acc: 0.7289 - val_loss: 1.1292 - val_acc: 0.6771\n",
            "Epoch 40/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.7700 - acc: 0.7306 - val_loss: 1.3014 - val_acc: 0.6536\n",
            "Epoch 41/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.7687 - acc: 0.7312 - val_loss: 1.0923 - val_acc: 0.6819\n",
            "Epoch 42/50\n",
            "468/468 [==============================] - 154s 328ms/step - loss: 0.7734 - acc: 0.7293 - val_loss: 1.1394 - val_acc: 0.6817\n",
            "Epoch 43/50\n",
            "468/468 [==============================] - 153s 328ms/step - loss: 0.7712 - acc: 0.7298 - val_loss: 1.3244 - val_acc: 0.6444\n",
            "Epoch 44/50\n",
            "468/468 [==============================] - 153s 327ms/step - loss: 0.7660 - acc: 0.7340 - val_loss: 1.2241 - val_acc: 0.6578\n",
            "Epoch 45/50\n",
            "468/468 [==============================] - 152s 325ms/step - loss: 0.7661 - acc: 0.7322 - val_loss: 1.1727 - val_acc: 0.6749\n",
            "Epoch 46/50\n",
            "468/468 [==============================] - 152s 324ms/step - loss: 0.7661 - acc: 0.7318 - val_loss: 1.0109 - val_acc: 0.7053\n",
            "Epoch 47/50\n",
            "468/468 [==============================] - 152s 325ms/step - loss: 0.7577 - acc: 0.7351 - val_loss: 0.9911 - val_acc: 0.7054\n",
            "Epoch 48/50\n",
            "468/468 [==============================] - 151s 324ms/step - loss: 0.7584 - acc: 0.7352 - val_loss: 1.0613 - val_acc: 0.6940\n",
            "Epoch 49/50\n",
            "468/468 [==============================] - 152s 325ms/step - loss: 0.7617 - acc: 0.7337 - val_loss: 1.1610 - val_acc: 0.6751\n",
            "Epoch 50/50\n",
            "468/468 [==============================] - 151s 323ms/step - loss: 0.7607 - acc: 0.7363 - val_loss: 0.9023 - val_acc: 0.7231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26fa65ee10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "bYdUSNZLyeh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "7271b79f-30c0-4c85-8f27-fa1545a5e2bf"
      },
      "cell_type": "code",
      "source": [
        "# adding another training for 50 epochs\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.6797 - acc: 0.7648 - val_loss: 0.8185 - val_acc: 0.7403\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6725 - acc: 0.7652 - val_loss: 0.9830 - val_acc: 0.7099\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6682 - acc: 0.7689 - val_loss: 0.9336 - val_acc: 0.7188\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6626 - acc: 0.7700 - val_loss: 1.0322 - val_acc: 0.7026\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6638 - acc: 0.7717 - val_loss: 0.8921 - val_acc: 0.7300\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6670 - acc: 0.7675 - val_loss: 1.1238 - val_acc: 0.6898\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6556 - acc: 0.7723 - val_loss: 0.8069 - val_acc: 0.7480\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6590 - acc: 0.7705 - val_loss: 0.9446 - val_acc: 0.7212\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.6624 - acc: 0.7685 - val_loss: 0.8112 - val_acc: 0.7449\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.6536 - acc: 0.7739 - val_loss: 1.1243 - val_acc: 0.6899\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.6524 - acc: 0.7742 - val_loss: 0.7483 - val_acc: 0.7640\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.6515 - acc: 0.7741 - val_loss: 0.9262 - val_acc: 0.7212\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6534 - acc: 0.7743 - val_loss: 0.8018 - val_acc: 0.7507\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6467 - acc: 0.7746 - val_loss: 0.8864 - val_acc: 0.7329\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6467 - acc: 0.7777 - val_loss: 0.7756 - val_acc: 0.7527\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6467 - acc: 0.7752 - val_loss: 0.8079 - val_acc: 0.7504\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6449 - acc: 0.7759 - val_loss: 0.8388 - val_acc: 0.7469\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6453 - acc: 0.7772 - val_loss: 0.8663 - val_acc: 0.7383\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6470 - acc: 0.7754 - val_loss: 0.7642 - val_acc: 0.7580\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6439 - acc: 0.7755 - val_loss: 0.7841 - val_acc: 0.7588\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6423 - acc: 0.7760 - val_loss: 0.8236 - val_acc: 0.7524\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6383 - acc: 0.7773 - val_loss: 0.9139 - val_acc: 0.7252\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6416 - acc: 0.7784 - val_loss: 0.8066 - val_acc: 0.7513\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.6295 - acc: 0.7808 - val_loss: 0.8760 - val_acc: 0.7414\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6389 - acc: 0.7775 - val_loss: 0.8048 - val_acc: 0.7563\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 0.6374 - acc: 0.7796 - val_loss: 1.0169 - val_acc: 0.7160\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6356 - acc: 0.7799 - val_loss: 0.8350 - val_acc: 0.7427\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6379 - acc: 0.7776 - val_loss: 0.7778 - val_acc: 0.7577\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6270 - acc: 0.7811 - val_loss: 0.9279 - val_acc: 0.7264\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6310 - acc: 0.7801 - val_loss: 0.8078 - val_acc: 0.7512\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6272 - acc: 0.7819 - val_loss: 0.8710 - val_acc: 0.7418\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6279 - acc: 0.7811 - val_loss: 0.9029 - val_acc: 0.7303\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6242 - acc: 0.7833 - val_loss: 0.8090 - val_acc: 0.7492\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6268 - acc: 0.7826 - val_loss: 0.7806 - val_acc: 0.7596\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6208 - acc: 0.7846 - val_loss: 0.8996 - val_acc: 0.7313\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6213 - acc: 0.7838 - val_loss: 0.9689 - val_acc: 0.7259\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6178 - acc: 0.7861 - val_loss: 0.9373 - val_acc: 0.7270\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6228 - acc: 0.7833 - val_loss: 0.7647 - val_acc: 0.7623\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6163 - acc: 0.7872 - val_loss: 0.9253 - val_acc: 0.7324\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6187 - acc: 0.7851 - val_loss: 0.8654 - val_acc: 0.7374\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6143 - acc: 0.7864 - val_loss: 0.7611 - val_acc: 0.7650\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6212 - acc: 0.7851 - val_loss: 0.8629 - val_acc: 0.7445\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6144 - acc: 0.7872 - val_loss: 0.8321 - val_acc: 0.7446\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6144 - acc: 0.7868 - val_loss: 0.9457 - val_acc: 0.7289\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6135 - acc: 0.7870 - val_loss: 0.8461 - val_acc: 0.7460\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6128 - acc: 0.7877 - val_loss: 0.7910 - val_acc: 0.7641\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6138 - acc: 0.7863 - val_loss: 0.9349 - val_acc: 0.7320\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6043 - acc: 0.7902 - val_loss: 0.7748 - val_acc: 0.7649\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6130 - acc: 0.7895 - val_loss: 0.7671 - val_acc: 0.7643\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.6119 - acc: 0.7896 - val_loss: 0.8118 - val_acc: 0.7581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26fa5dcfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d35c87a5-cabf-44aa-a8ff-a8b872a2fa5b"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 12s 1ms/step\n",
            "Test loss: 0.8118465921878815\n",
            "Test accuracy: 0.7581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "124d903e-07b8-40b6-b8af-8cec0805d3ee"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}