{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 4 Assignment DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cda6b0ad-3eb1-4345-c067-8d50305b6ab4"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128 #128 - original batch size\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cff30f3b-e205-4072-d782-8b2bc6a02b1a"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "#print (img_height, img_width, channel)\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 41s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 16  \n",
        "# original is 12 \n",
        "# 64, 128 and 256 are giving above 1MM+ Parameters, hence going with 32.\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Fourth_Block = add_denseblock(Third_Transition, num_filter, dropout_rate)\n",
        "Fourth_Transition = add_transition(Fourth_Block, num_filter, dropout_rate)\n",
        "\n",
        "#Fifth_Block = add_denseblock(Fourth_Transition, num_filter, dropout_rate)\n",
        "#Fifth_Transition = add_transition(Fifth_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Fourth_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12274
        },
        "outputId": "074372d1-0520-47c9-e769-143f1b6b3fa1"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 32, 32, 16)   432         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 32, 32, 16)   64          conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 32, 32, 16)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 32, 32, 8)    1152        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 32, 32, 8)    0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 32, 32, 24)   0           conv2d_79[0][0]                  \n",
            "                                                                 dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 32, 32, 24)   96          concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 32, 32, 24)   0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 32, 32, 8)    1728        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 32, 32, 8)    0           conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 32, 32, 32)   0           concatenate_73[0][0]             \n",
            "                                                                 dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 32, 32, 32)   128         concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 32, 32, 32)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 32, 32, 8)    2304        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 32, 32, 8)    0           conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 32, 32, 40)   0           concatenate_74[0][0]             \n",
            "                                                                 dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 32, 32, 40)   160         concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 32, 32, 40)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 32, 32, 8)    2880        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 32, 32, 8)    0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 32, 32, 48)   0           concatenate_75[0][0]             \n",
            "                                                                 dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 32, 32, 48)   192         concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 32, 32, 48)   0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 32, 32, 8)    3456        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 32, 32, 8)    0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 32, 32, 56)   0           concatenate_76[0][0]             \n",
            "                                                                 dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 32, 32, 56)   224         concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 32, 32, 56)   0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 8)    4032        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 32, 32, 8)    0           conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 32, 32, 64)   0           concatenate_77[0][0]             \n",
            "                                                                 dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 32, 32, 64)   256         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 32, 32, 64)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 8)    4608        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 32, 32, 8)    0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 32, 32, 72)   0           concatenate_78[0][0]             \n",
            "                                                                 dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 32, 32, 72)   288         concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 32, 32, 72)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 8)    5184        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 32, 32, 8)    0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 32, 32, 80)   0           concatenate_79[0][0]             \n",
            "                                                                 dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 32, 32, 80)   320         concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 32, 32, 80)   0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 8)    5760        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 32, 32, 8)    0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 32, 32, 88)   0           concatenate_80[0][0]             \n",
            "                                                                 dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 32, 32, 88)   352         concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 32, 32, 88)   0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 8)    6336        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 32, 32, 8)    0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 32, 32, 96)   0           concatenate_81[0][0]             \n",
            "                                                                 dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 32, 32, 96)   384         concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 32, 32, 96)   0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 32, 32, 8)    6912        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 32, 32, 8)    0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 32, 32, 104)  0           concatenate_82[0][0]             \n",
            "                                                                 dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 32, 32, 104)  416         concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 32, 32, 104)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 32, 32, 8)    7488        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 32, 32, 8)    0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 32, 32, 112)  0           concatenate_83[0][0]             \n",
            "                                                                 dropout_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 32, 32, 112)  448         concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 32, 32, 112)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 32, 32, 8)    896         activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, 32, 32, 8)    0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 16, 16, 8)    0           dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 16, 16, 8)    32          average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 16, 16, 8)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 16, 16, 8)    576         activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, 16, 16, 8)    0           conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_85 (Concatenate)    (None, 16, 16, 16)   0           average_pooling2d_7[0][0]        \n",
            "                                                                 dropout_91[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 16, 16, 16)   64          concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 16, 16, 16)   0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 16, 16, 8)    1152        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 16, 16, 8)    0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_86 (Concatenate)    (None, 16, 16, 24)   0           concatenate_85[0][0]             \n",
            "                                                                 dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 16, 16, 24)   96          concatenate_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 16, 16, 24)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 16, 16, 8)    1728        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 16, 16, 8)    0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_87 (Concatenate)    (None, 16, 16, 32)   0           concatenate_86[0][0]             \n",
            "                                                                 dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 16, 16, 32)   128         concatenate_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 16, 16, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 16, 16, 8)    2304        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 16, 16, 8)    0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_88 (Concatenate)    (None, 16, 16, 40)   0           concatenate_87[0][0]             \n",
            "                                                                 dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 16, 16, 40)   160         concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 16, 16, 40)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 16, 16, 8)    2880        activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 16, 16, 8)    0           conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_89 (Concatenate)    (None, 16, 16, 48)   0           concatenate_88[0][0]             \n",
            "                                                                 dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 16, 16, 48)   192         concatenate_89[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 16, 16, 48)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 16, 16, 8)    3456        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 16, 16, 8)    0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_90 (Concatenate)    (None, 16, 16, 56)   0           concatenate_89[0][0]             \n",
            "                                                                 dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 16, 16, 56)   224         concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 16, 16, 56)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 8)    4032        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 16, 16, 8)    0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 16, 16, 64)   0           concatenate_90[0][0]             \n",
            "                                                                 dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   256         concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 8)    4608        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 16, 16, 8)    0           conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 16, 16, 72)   0           concatenate_91[0][0]             \n",
            "                                                                 dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 72)   288         concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 72)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 8)    5184        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 16, 16, 8)    0           conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 16, 16, 80)   0           concatenate_92[0][0]             \n",
            "                                                                 dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 80)   320         concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 80)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 8)    5760        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, 16, 16, 8)    0           conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 16, 16, 88)   0           concatenate_93[0][0]             \n",
            "                                                                 dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 88)   352         concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 88)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 8)    6336        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 16, 16, 8)    0           conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_95 (Concatenate)    (None, 16, 16, 96)   0           concatenate_94[0][0]             \n",
            "                                                                 dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   384         concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 8)    6912        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 16, 16, 8)    0           conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_96 (Concatenate)    (None, 16, 16, 104)  0           concatenate_95[0][0]             \n",
            "                                                                 dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 104)  416         concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 104)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 8)    832         activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 16, 16, 8)    0           conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 8)      0           dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 8, 8, 8)      32          average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 8, 8, 8)      0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 8, 8, 8)      576         activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 8, 8, 8)      0           conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 8, 8, 16)     0           average_pooling2d_8[0][0]        \n",
            "                                                                 dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 8, 8, 16)     64          concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 8, 8, 16)     0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 8, 8, 8)      1152        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 8, 8, 8)      0           conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 8, 8, 24)     0           concatenate_97[0][0]             \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 8, 8, 24)     96          concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 8, 8, 24)     0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 8, 8, 8)      1728        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 8, 8, 8)      0           conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 8, 8, 32)     0           concatenate_98[0][0]             \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 8, 8, 32)     128         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 8, 8, 32)     0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 8, 8, 8)      2304        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 8, 8, 8)      0           conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 8, 8, 40)     0           concatenate_99[0][0]             \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 8, 8, 40)     160         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 8, 8, 40)     0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 8, 8, 8)      2880        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 8, 8, 8)      0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 8, 8, 48)     0           concatenate_100[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 8, 8, 48)     192         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 8, 8, 48)     0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 8, 8, 8)      3456        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 8, 8, 8)      0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 8, 8, 56)     0           concatenate_101[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 8, 8, 56)     224         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 8, 8, 56)     0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 8, 8, 8)      4032        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 8, 8, 8)      0           conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 8, 8, 64)     0           concatenate_102[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 8, 8, 64)     256         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 8, 8, 64)     0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 8, 8, 8)      4608        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 8, 8, 8)      0           conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 8, 8, 72)     0           concatenate_103[0][0]            \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 8, 8, 72)     288         concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 8, 8, 72)     0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 8, 8, 8)      5184        activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 8, 8, 8)      0           conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 8, 8, 80)     0           concatenate_104[0][0]            \n",
            "                                                                 dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 8, 8, 80)     320         concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 8, 8, 80)     0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 8, 8, 8)      5760        activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 8, 8, 8)      0           conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 8, 8, 88)     0           concatenate_105[0][0]            \n",
            "                                                                 dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 8, 8, 88)     352         concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 8, 8, 88)     0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 8, 8, 8)      6336        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 8, 8, 8)      0           conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 8, 8, 96)     0           concatenate_106[0][0]            \n",
            "                                                                 dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 8, 8, 96)     384         concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 8, 8, 96)     0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 8, 8, 8)      6912        activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 8, 8, 8)      0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 8, 8, 104)    0           concatenate_107[0][0]            \n",
            "                                                                 dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 8, 8, 104)    416         concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 8, 8, 104)    0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 8, 8, 8)      832         activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 8, 8, 8)      0           conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 4, 4, 8)      0           dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 4, 4, 8)      32          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 4, 4, 8)      0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 4, 4, 8)      576         activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 4, 4, 8)      0           conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 4, 4, 16)     0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 4, 4, 16)     64          concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 4, 4, 16)     0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 4, 4, 8)      1152        activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 4, 4, 8)      0           conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 4, 4, 24)     0           concatenate_109[0][0]            \n",
            "                                                                 dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 4, 4, 24)     96          concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 4, 4, 24)     0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 4, 4, 8)      1728        activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 4, 4, 8)      0           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 4, 4, 32)     0           concatenate_110[0][0]            \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 4, 4, 32)     128         concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 4, 4, 32)     0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 4, 4, 8)      2304        activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 4, 4, 8)      0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 4, 4, 40)     0           concatenate_111[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 4, 4, 40)     160         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 4, 4, 40)     0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 4, 4, 8)      2880        activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 4, 4, 8)      0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 4, 4, 48)     0           concatenate_112[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 4, 4, 48)     192         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 4, 4, 48)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 4, 4, 8)      3456        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 4, 4, 8)      0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 4, 4, 56)     0           concatenate_113[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 4, 4, 56)     224         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 4, 4, 56)     0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 4, 4, 8)      4032        activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 4, 4, 8)      0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 4, 4, 64)     0           concatenate_114[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 4, 4, 64)     256         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 4, 4, 64)     0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 4, 4, 8)      4608        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 4, 4, 8)      0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 4, 4, 72)     0           concatenate_115[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 4, 4, 72)     288         concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 4, 4, 72)     0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 4, 4, 8)      5184        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 4, 4, 8)      0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 4, 4, 80)     0           concatenate_116[0][0]            \n",
            "                                                                 dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 4, 4, 80)     320         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 4, 4, 80)     0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 4, 4, 8)      5760        activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 4, 4, 8)      0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 4, 4, 88)     0           concatenate_117[0][0]            \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 4, 4, 88)     352         concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 4, 4, 88)     0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 4, 4, 8)      6336        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 4, 4, 8)      0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 4, 4, 96)     0           concatenate_118[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 4, 4, 96)     384         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 4, 4, 96)     0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 4, 4, 8)      6912        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 4, 4, 8)      0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 4, 4, 104)    0           concatenate_119[0][0]            \n",
            "                                                                 dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 4, 4, 104)    416         concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 4, 4, 104)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 4, 4, 8)      832         activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 4, 4, 8)      0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 2, 2, 8)      0           dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 2, 2, 8)      32          average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 2, 2, 8)      0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 2, 2, 8)      576         activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 2, 2, 8)      0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 2, 2, 16)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 2, 2, 16)     64          concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 2, 2, 16)     0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 2, 2, 8)      1152        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 2, 2, 8)      0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 2, 2, 24)     0           concatenate_121[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 2, 2, 24)     96          concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 2, 2, 24)     0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 2, 2, 8)      1728        activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 2, 2, 8)      0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 2, 2, 32)     0           concatenate_122[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 2, 2, 32)     128         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 2, 2, 32)     0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 2, 2, 8)      2304        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 2, 2, 8)      0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 2, 2, 40)     0           concatenate_123[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 2, 2, 40)     160         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 2, 2, 40)     0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 2, 2, 8)      2880        activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 2, 2, 8)      0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 2, 2, 48)     0           concatenate_124[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 2, 2, 48)     192         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 2, 2, 48)     0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 2, 2, 8)      3456        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 2, 2, 8)      0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 2, 2, 56)     0           concatenate_125[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 2, 2, 56)     224         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 2, 2, 56)     0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 2, 2, 8)      4032        activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 2, 2, 8)      0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 2, 2, 64)     0           concatenate_126[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 2, 2, 64)     256         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 2, 2, 64)     0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 2, 2, 8)      4608        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 2, 2, 8)      0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 2, 2, 72)     0           concatenate_127[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 2, 2, 72)     288         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 2, 2, 72)     0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 2, 2, 8)      5184        activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 2, 2, 8)      0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 2, 2, 80)     0           concatenate_128[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 2, 2, 80)     320         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 2, 2, 80)     0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 2, 2, 8)      5760        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 2, 2, 8)      0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 2, 2, 88)     0           concatenate_129[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 2, 2, 88)     352         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 2, 2, 88)     0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 2, 2, 8)      6336        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 2, 2, 8)      0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 2, 2, 96)     0           concatenate_130[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 2, 2, 96)     384         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 2, 2, 96)     0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 2, 2, 8)      6912        activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 2, 2, 8)      0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 2, 2, 104)    0           concatenate_131[0][0]            \n",
            "                                                                 dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 2, 2, 104)    416         concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 2, 2, 104)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 1, 1, 104)    0           activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 104)          0           average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           1050        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 251,402\n",
            "Trainable params: 243,914\n",
            "Non-trainable params: 7,488\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.1),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rF3jNDdfvx-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        },
        "outputId": "f76a6a28-3c33-45a8-ba22-ce0fda77337b"
      },
      "cell_type": "code",
      "source": [
        "# Adding Image Augmentation\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.1, zoom_range=0.1)\n",
        "\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
        "test_generator = test_gen.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=60000//batch_size, epochs=epochs, validation_data=test_generator, validation_steps=10000//batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "468/468 [==============================] - 182s 389ms/step - loss: 1.8750 - acc: 0.2875 - val_loss: 1.7092 - val_acc: 0.3697\n",
            "Epoch 2/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 1.5923 - acc: 0.4028 - val_loss: 1.8160 - val_acc: 0.3973\n",
            "Epoch 3/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 1.4513 - acc: 0.4631 - val_loss: 1.4562 - val_acc: 0.4833\n",
            "Epoch 4/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.3490 - acc: 0.5080 - val_loss: 1.6189 - val_acc: 0.4607\n",
            "Epoch 5/50\n",
            "468/468 [==============================] - 159s 339ms/step - loss: 1.2728 - acc: 0.5393 - val_loss: 1.5164 - val_acc: 0.5144\n",
            "Epoch 6/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.2151 - acc: 0.5619 - val_loss: 1.2245 - val_acc: 0.5692\n",
            "Epoch 7/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.1589 - acc: 0.5821 - val_loss: 1.3357 - val_acc: 0.5664\n",
            "Epoch 8/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 1.1108 - acc: 0.6013 - val_loss: 1.4745 - val_acc: 0.5626\n",
            "Epoch 9/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.0765 - acc: 0.6149 - val_loss: 1.3022 - val_acc: 0.5861\n",
            "Epoch 10/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 1.0344 - acc: 0.6292 - val_loss: 1.2014 - val_acc: 0.6169\n",
            "Epoch 11/50\n",
            "468/468 [==============================] - 157s 336ms/step - loss: 1.0086 - acc: 0.6397 - val_loss: 1.2828 - val_acc: 0.6060\n",
            "Epoch 12/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.9763 - acc: 0.6523 - val_loss: 1.4410 - val_acc: 0.5839\n",
            "Epoch 13/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.9480 - acc: 0.6628 - val_loss: 1.2920 - val_acc: 0.6127\n",
            "Epoch 14/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.9220 - acc: 0.6719 - val_loss: 1.1605 - val_acc: 0.6423\n",
            "Epoch 15/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.8992 - acc: 0.6831 - val_loss: 1.4047 - val_acc: 0.5974\n",
            "Epoch 16/50\n",
            "468/468 [==============================] - 157s 336ms/step - loss: 0.8864 - acc: 0.6861 - val_loss: 1.6231 - val_acc: 0.5679\n",
            "Epoch 17/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.8611 - acc: 0.6944 - val_loss: 0.9002 - val_acc: 0.6994\n",
            "Epoch 18/50\n",
            "468/468 [==============================] - 157s 336ms/step - loss: 0.8468 - acc: 0.7000 - val_loss: 1.1769 - val_acc: 0.6417\n",
            "Epoch 19/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.8292 - acc: 0.7067 - val_loss: 1.4028 - val_acc: 0.6031\n",
            "Epoch 20/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.8120 - acc: 0.7156 - val_loss: 0.8403 - val_acc: 0.7198\n",
            "Epoch 21/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.8014 - acc: 0.7180 - val_loss: 1.0126 - val_acc: 0.6893\n",
            "Epoch 22/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.7830 - acc: 0.7257 - val_loss: 0.8820 - val_acc: 0.7138\n",
            "Epoch 23/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.7709 - acc: 0.7284 - val_loss: 1.1644 - val_acc: 0.6580\n",
            "Epoch 24/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.7617 - acc: 0.7350 - val_loss: 0.9285 - val_acc: 0.7050\n",
            "Epoch 25/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.7505 - acc: 0.7384 - val_loss: 1.0553 - val_acc: 0.6907\n",
            "Epoch 26/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.7374 - acc: 0.7420 - val_loss: 1.0009 - val_acc: 0.7029\n",
            "Epoch 27/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.7310 - acc: 0.7460 - val_loss: 0.9671 - val_acc: 0.7086\n",
            "Epoch 28/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.7124 - acc: 0.7514 - val_loss: 0.8065 - val_acc: 0.7461\n",
            "Epoch 29/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.7125 - acc: 0.7530 - val_loss: 0.8951 - val_acc: 0.7295\n",
            "Epoch 30/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.6999 - acc: 0.7575 - val_loss: 0.9814 - val_acc: 0.7143\n",
            "Epoch 31/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.6912 - acc: 0.7600 - val_loss: 0.8960 - val_acc: 0.7347\n",
            "Epoch 32/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6812 - acc: 0.7620 - val_loss: 0.9569 - val_acc: 0.7135\n",
            "Epoch 33/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6677 - acc: 0.7685 - val_loss: 0.8146 - val_acc: 0.7489\n",
            "Epoch 34/50\n",
            "468/468 [==============================] - 157s 336ms/step - loss: 0.6633 - acc: 0.7684 - val_loss: 0.7836 - val_acc: 0.7622\n",
            "Epoch 35/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6552 - acc: 0.7728 - val_loss: 0.8005 - val_acc: 0.7594\n",
            "Epoch 36/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6504 - acc: 0.7752 - val_loss: 1.0213 - val_acc: 0.7065\n",
            "Epoch 37/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6379 - acc: 0.7779 - val_loss: 1.0155 - val_acc: 0.7158\n",
            "Epoch 38/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.6327 - acc: 0.7821 - val_loss: 0.8499 - val_acc: 0.7414\n",
            "Epoch 39/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6324 - acc: 0.7809 - val_loss: 1.1280 - val_acc: 0.7014\n",
            "Epoch 40/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6232 - acc: 0.7849 - val_loss: 0.7446 - val_acc: 0.7726\n",
            "Epoch 41/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6182 - acc: 0.7874 - val_loss: 0.8810 - val_acc: 0.7430\n",
            "Epoch 42/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.6115 - acc: 0.7880 - val_loss: 0.9386 - val_acc: 0.7286\n",
            "Epoch 43/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.6027 - acc: 0.7919 - val_loss: 0.7616 - val_acc: 0.7724\n",
            "Epoch 44/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.6046 - acc: 0.7905 - val_loss: 0.7163 - val_acc: 0.7830\n",
            "Epoch 45/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.5996 - acc: 0.7932 - val_loss: 0.6834 - val_acc: 0.7919\n",
            "Epoch 46/50\n",
            "468/468 [==============================] - 157s 337ms/step - loss: 0.5863 - acc: 0.7971 - val_loss: 0.9053 - val_acc: 0.7505\n",
            "Epoch 47/50\n",
            "468/468 [==============================] - 158s 338ms/step - loss: 0.5828 - acc: 0.8000 - val_loss: 0.8275 - val_acc: 0.7536\n",
            "Epoch 48/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.5769 - acc: 0.8005 - val_loss: 0.7253 - val_acc: 0.7825\n",
            "Epoch 49/50\n",
            "468/468 [==============================] - 158s 337ms/step - loss: 0.5757 - acc: 0.8004 - val_loss: 0.8498 - val_acc: 0.7653\n",
            "Epoch 50/50\n",
            "468/468 [==============================] - 159s 339ms/step - loss: 0.5694 - acc: 0.8028 - val_loss: 0.7982 - val_acc: 0.7759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1f3179828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "94e89a39-16ce-450d-ec78-0f047c76d6d3"
      },
      "cell_type": "code",
      "source": [
        "# Model fit implimentation that came with original code\n",
        "# Runnig for 50 epochs\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4903 - acc: 0.8304 - val_loss: 0.6809 - val_acc: 0.7951\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4800 - acc: 0.8352 - val_loss: 0.5856 - val_acc: 0.8196\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4737 - acc: 0.8369 - val_loss: 0.6372 - val_acc: 0.8050\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4706 - acc: 0.8370 - val_loss: 0.6932 - val_acc: 0.7999\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4696 - acc: 0.8393 - val_loss: 0.8737 - val_acc: 0.7634\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4604 - acc: 0.8414 - val_loss: 0.7492 - val_acc: 0.7833\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4572 - acc: 0.8441 - val_loss: 0.7024 - val_acc: 0.8038\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4546 - acc: 0.8434 - val_loss: 0.7526 - val_acc: 0.7839\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4481 - acc: 0.8449 - val_loss: 0.7235 - val_acc: 0.7928\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4497 - acc: 0.8445 - val_loss: 0.9544 - val_acc: 0.7460\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4418 - acc: 0.8460 - val_loss: 0.9193 - val_acc: 0.7511\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4401 - acc: 0.8482 - val_loss: 0.8153 - val_acc: 0.7711\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4365 - acc: 0.8503 - val_loss: 0.9217 - val_acc: 0.7585\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4345 - acc: 0.8488 - val_loss: 0.5786 - val_acc: 0.8236\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4296 - acc: 0.8507 - val_loss: 0.8552 - val_acc: 0.7720\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4306 - acc: 0.8521 - val_loss: 0.6090 - val_acc: 0.8208\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4230 - acc: 0.8542 - val_loss: 0.5980 - val_acc: 0.8208\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4243 - acc: 0.8527 - val_loss: 0.8393 - val_acc: 0.7686\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4187 - acc: 0.8547 - val_loss: 0.8378 - val_acc: 0.7774\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4173 - acc: 0.8543 - val_loss: 0.7732 - val_acc: 0.7862\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4148 - acc: 0.8550 - val_loss: 0.5923 - val_acc: 0.8260\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4122 - acc: 0.8567 - val_loss: 0.7652 - val_acc: 0.7886\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4051 - acc: 0.8609 - val_loss: 0.5755 - val_acc: 0.8318\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4062 - acc: 0.8592 - val_loss: 0.6906 - val_acc: 0.7968\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4052 - acc: 0.8599 - val_loss: 0.7056 - val_acc: 0.8067\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4023 - acc: 0.8620 - val_loss: 0.6906 - val_acc: 0.8121\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.4017 - acc: 0.8616 - val_loss: 0.6844 - val_acc: 0.8095\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3970 - acc: 0.8646 - val_loss: 0.8844 - val_acc: 0.7648\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3953 - acc: 0.8629 - val_loss: 0.5597 - val_acc: 0.8339\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3937 - acc: 0.8624 - val_loss: 0.6216 - val_acc: 0.8220\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3909 - acc: 0.8639 - val_loss: 0.8032 - val_acc: 0.7852\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3867 - acc: 0.8664 - val_loss: 0.5823 - val_acc: 0.8331\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3877 - acc: 0.8647 - val_loss: 0.5841 - val_acc: 0.8330\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3852 - acc: 0.8688 - val_loss: 0.6885 - val_acc: 0.8143\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3805 - acc: 0.8687 - val_loss: 0.7002 - val_acc: 0.8075\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3793 - acc: 0.8685 - val_loss: 0.6904 - val_acc: 0.8073\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3786 - acc: 0.8686 - val_loss: 0.6356 - val_acc: 0.8243\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3739 - acc: 0.8703 - val_loss: 0.8000 - val_acc: 0.7868\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3760 - acc: 0.8709 - val_loss: 0.6276 - val_acc: 0.8239\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3722 - acc: 0.8708 - val_loss: 0.6425 - val_acc: 0.8137\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3690 - acc: 0.8709 - val_loss: 0.5434 - val_acc: 0.8381\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3660 - acc: 0.8745 - val_loss: 0.6052 - val_acc: 0.8337\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3636 - acc: 0.8745 - val_loss: 0.5899 - val_acc: 0.8337\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3618 - acc: 0.8762 - val_loss: 0.6100 - val_acc: 0.8267\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3630 - acc: 0.8739 - val_loss: 0.9269 - val_acc: 0.7608\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3573 - acc: 0.8765 - val_loss: 0.7483 - val_acc: 0.7962\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3557 - acc: 0.8757 - val_loss: 0.6427 - val_acc: 0.8282\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3581 - acc: 0.8761 - val_loss: 0.6316 - val_acc: 0.8234\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3551 - acc: 0.8755 - val_loss: 0.6388 - val_acc: 0.8306\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3525 - acc: 0.8773 - val_loss: 0.8182 - val_acc: 0.7931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1f30f7a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "wksM_-92nkOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "a0faf5ab-5996-4de8-ffd3-1849861bf030"
      },
      "cell_type": "code",
      "source": [
        "# Running for 25 epochs\n",
        "#model.fit_generator(train_generator, steps_per_epoch=60000//batch_size, epochs=epochs//2, validation_data=test_generator, validation_steps=10000//batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "468/468 [==============================] - 268s 573ms/step - loss: 0.5027 - acc: 0.8271 - val_loss: 0.7950 - val_acc: 0.7809\n",
            "Epoch 2/25\n",
            "468/468 [==============================] - 268s 573ms/step - loss: 0.5016 - acc: 0.8292 - val_loss: 0.7699 - val_acc: 0.7894\n",
            "Epoch 3/25\n",
            "468/468 [==============================] - 269s 574ms/step - loss: 0.4847 - acc: 0.8317 - val_loss: 0.6935 - val_acc: 0.8021\n",
            "Epoch 4/25\n",
            "468/468 [==============================] - 269s 574ms/step - loss: 0.4812 - acc: 0.8325 - val_loss: 0.7994 - val_acc: 0.7820\n",
            "Epoch 5/25\n",
            "468/468 [==============================] - 268s 573ms/step - loss: 0.4766 - acc: 0.8355 - val_loss: 0.7693 - val_acc: 0.7950\n",
            "Epoch 6/25\n",
            "468/468 [==============================] - 269s 574ms/step - loss: 0.4777 - acc: 0.8359 - val_loss: 0.8063 - val_acc: 0.7800\n",
            "Epoch 7/25\n",
            "468/468 [==============================] - 269s 574ms/step - loss: 0.4666 - acc: 0.8400 - val_loss: 0.7514 - val_acc: 0.7926\n",
            "Epoch 8/25\n",
            "468/468 [==============================] - 270s 577ms/step - loss: 0.4713 - acc: 0.8373 - val_loss: 0.8056 - val_acc: 0.7819\n",
            "Epoch 9/25\n",
            "468/468 [==============================] - 270s 577ms/step - loss: 0.4662 - acc: 0.8396 - val_loss: 0.9849 - val_acc: 0.7501\n",
            "Epoch 10/25\n",
            "468/468 [==============================] - 270s 577ms/step - loss: 0.4575 - acc: 0.8408 - val_loss: 0.6488 - val_acc: 0.8174\n",
            "Epoch 11/25\n",
            "468/468 [==============================] - 269s 576ms/step - loss: 0.4556 - acc: 0.8427 - val_loss: 0.6305 - val_acc: 0.8195\n",
            "Epoch 12/25\n",
            "468/468 [==============================] - 269s 575ms/step - loss: 0.4598 - acc: 0.8408 - val_loss: 0.7492 - val_acc: 0.7989\n",
            "Epoch 13/25\n",
            "468/468 [==============================] - 270s 576ms/step - loss: 0.4556 - acc: 0.8426 - val_loss: 0.6838 - val_acc: 0.8136\n",
            "Epoch 14/25\n",
            "468/468 [==============================] - 269s 575ms/step - loss: 0.4503 - acc: 0.8443 - val_loss: 0.7676 - val_acc: 0.7991\n",
            "Epoch 15/25\n",
            "468/468 [==============================] - 269s 575ms/step - loss: 0.4523 - acc: 0.8458 - val_loss: 0.7991 - val_acc: 0.7904\n",
            "Epoch 16/25\n",
            "468/468 [==============================] - 270s 576ms/step - loss: 0.4426 - acc: 0.8476 - val_loss: 0.7095 - val_acc: 0.8041\n",
            "Epoch 17/25\n",
            "468/468 [==============================] - 270s 576ms/step - loss: 0.4409 - acc: 0.8471 - val_loss: 0.7583 - val_acc: 0.7915\n",
            "Epoch 18/25\n",
            "468/468 [==============================] - 270s 576ms/step - loss: 0.4390 - acc: 0.8491 - val_loss: 0.7378 - val_acc: 0.8034\n",
            "Epoch 19/25\n",
            "468/468 [==============================] - 270s 576ms/step - loss: 0.4440 - acc: 0.8475 - val_loss: 0.6742 - val_acc: 0.8110\n",
            "Epoch 20/25\n",
            "468/468 [==============================] - 269s 576ms/step - loss: 0.4338 - acc: 0.8495 - val_loss: 0.6980 - val_acc: 0.8127\n",
            "Epoch 21/25\n",
            "468/468 [==============================] - 269s 576ms/step - loss: 0.4338 - acc: 0.8503 - val_loss: 0.6435 - val_acc: 0.8251\n",
            "Epoch 22/25\n",
            "468/468 [==============================] - 270s 576ms/step - loss: 0.4276 - acc: 0.8532 - val_loss: 0.6732 - val_acc: 0.8138\n",
            "Epoch 23/25\n",
            "468/468 [==============================] - 269s 575ms/step - loss: 0.4254 - acc: 0.8543 - val_loss: 0.7297 - val_acc: 0.8086\n",
            "Epoch 24/25\n",
            "468/468 [==============================] - 269s 576ms/step - loss: 0.4267 - acc: 0.8529 - val_loss: 0.7535 - val_acc: 0.8039\n",
            "Epoch 25/25\n",
            "468/468 [==============================] - 269s 575ms/step - loss: 0.4171 - acc: 0.8583 - val_loss: 0.8905 - val_acc: 0.7746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa3d372b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "bYdUSNZLyeh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        },
        "outputId": "8f2d767b-d8fd-468e-f039-ce525f46a5ab"
      },
      "cell_type": "code",
      "source": [
        "# adding another training for 50 epochs\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3485 - acc: 0.8793 - val_loss: 0.5949 - val_acc: 0.8373\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3448 - acc: 0.8802 - val_loss: 0.5180 - val_acc: 0.8501\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3491 - acc: 0.8794 - val_loss: 0.6392 - val_acc: 0.8243\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3469 - acc: 0.8790 - val_loss: 0.9834 - val_acc: 0.7659\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3456 - acc: 0.8797 - val_loss: 0.6603 - val_acc: 0.8241\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3424 - acc: 0.8798 - val_loss: 0.7536 - val_acc: 0.8094\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3430 - acc: 0.8812 - val_loss: 0.5699 - val_acc: 0.8392\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3412 - acc: 0.8829 - val_loss: 0.6432 - val_acc: 0.8278\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3386 - acc: 0.8811 - val_loss: 0.5645 - val_acc: 0.8452\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3352 - acc: 0.8827 - val_loss: 0.6470 - val_acc: 0.8291\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3377 - acc: 0.8823 - val_loss: 0.6890 - val_acc: 0.8182\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3298 - acc: 0.8846 - val_loss: 0.5670 - val_acc: 0.8394\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3378 - acc: 0.8831 - val_loss: 0.6322 - val_acc: 0.8255\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3287 - acc: 0.8848 - val_loss: 0.7162 - val_acc: 0.8113\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3291 - acc: 0.8863 - val_loss: 0.8255 - val_acc: 0.7975\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3334 - acc: 0.8838 - val_loss: 0.6845 - val_acc: 0.8187\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3224 - acc: 0.8879 - val_loss: 0.7079 - val_acc: 0.8164\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3261 - acc: 0.8877 - val_loss: 0.6586 - val_acc: 0.8247\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3223 - acc: 0.8878 - val_loss: 0.6769 - val_acc: 0.8245\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3270 - acc: 0.8865 - val_loss: 0.9718 - val_acc: 0.7667\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3240 - acc: 0.8889 - val_loss: 0.8057 - val_acc: 0.8005\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3199 - acc: 0.8894 - val_loss: 0.6689 - val_acc: 0.8223\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3198 - acc: 0.8883 - val_loss: 0.7596 - val_acc: 0.8088\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3212 - acc: 0.8874 - val_loss: 0.6300 - val_acc: 0.8361\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3190 - acc: 0.8890 - val_loss: 0.6670 - val_acc: 0.8215\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3159 - acc: 0.8887 - val_loss: 0.7714 - val_acc: 0.8081\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3167 - acc: 0.8888 - val_loss: 0.6289 - val_acc: 0.8354\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3123 - acc: 0.8912 - val_loss: 0.5772 - val_acc: 0.8409\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3158 - acc: 0.8904 - val_loss: 0.7545 - val_acc: 0.8065\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3110 - acc: 0.8923 - val_loss: 0.6486 - val_acc: 0.8295\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3135 - acc: 0.8909 - val_loss: 0.6636 - val_acc: 0.8291\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3112 - acc: 0.8920 - val_loss: 0.7006 - val_acc: 0.8176\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3115 - acc: 0.8920 - val_loss: 0.7256 - val_acc: 0.8192\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3079 - acc: 0.8938 - val_loss: 0.5615 - val_acc: 0.8508\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3083 - acc: 0.8928 - val_loss: 0.7028 - val_acc: 0.8245\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3082 - acc: 0.8921 - val_loss: 0.5781 - val_acc: 0.8471\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3075 - acc: 0.8937 - val_loss: 0.5881 - val_acc: 0.8422\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3055 - acc: 0.8932 - val_loss: 0.8395 - val_acc: 0.8079\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.3048 - acc: 0.8950 - val_loss: 0.9602 - val_acc: 0.7811\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3045 - acc: 0.8934 - val_loss: 0.6342 - val_acc: 0.8356\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3036 - acc: 0.8935 - val_loss: 0.7302 - val_acc: 0.8136\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.3005 - acc: 0.8955 - val_loss: 0.6655 - val_acc: 0.8307\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2990 - acc: 0.8951 - val_loss: 0.6342 - val_acc: 0.8378\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2926 - acc: 0.8982 - val_loss: 0.5636 - val_acc: 0.8499\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2930 - acc: 0.8979 - val_loss: 0.6538 - val_acc: 0.8323\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2977 - acc: 0.8956 - val_loss: 0.6929 - val_acc: 0.8234\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2952 - acc: 0.8967 - val_loss: 0.6516 - val_acc: 0.8311\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2933 - acc: 0.8987 - val_loss: 0.5687 - val_acc: 0.8468\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2918 - acc: 0.8989 - val_loss: 0.6630 - val_acc: 0.8304\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2943 - acc: 0.8977 - val_loss: 0.7240 - val_acc: 0.8157\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2895 - acc: 0.8988 - val_loss: 0.7267 - val_acc: 0.8226\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2900 - acc: 0.8979 - val_loss: 0.6646 - val_acc: 0.8318\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2886 - acc: 0.8981 - val_loss: 0.6482 - val_acc: 0.8364\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2861 - acc: 0.9006 - val_loss: 0.5694 - val_acc: 0.8523\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2860 - acc: 0.9007 - val_loss: 0.5608 - val_acc: 0.8500\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2863 - acc: 0.9006 - val_loss: 0.6241 - val_acc: 0.8406\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2854 - acc: 0.9010 - val_loss: 0.8793 - val_acc: 0.7924\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2831 - acc: 0.9024 - val_loss: 0.5764 - val_acc: 0.8388\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2851 - acc: 0.9004 - val_loss: 0.7455 - val_acc: 0.8138\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2845 - acc: 0.9017 - val_loss: 0.6880 - val_acc: 0.8309\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2798 - acc: 0.9030 - val_loss: 0.6415 - val_acc: 0.8382\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2804 - acc: 0.9006 - val_loss: 0.7956 - val_acc: 0.8089\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2813 - acc: 0.9015 - val_loss: 0.7040 - val_acc: 0.8237\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2848 - acc: 0.9006 - val_loss: 0.6142 - val_acc: 0.8392\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2778 - acc: 0.9025 - val_loss: 0.5575 - val_acc: 0.8567\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2783 - acc: 0.9031 - val_loss: 0.8022 - val_acc: 0.8061\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2792 - acc: 0.9025 - val_loss: 0.7363 - val_acc: 0.8212\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2766 - acc: 0.9043 - val_loss: 0.6178 - val_acc: 0.8414\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2746 - acc: 0.9047 - val_loss: 0.6566 - val_acc: 0.8292\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2774 - acc: 0.9025 - val_loss: 0.5958 - val_acc: 0.8476\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2761 - acc: 0.9036 - val_loss: 0.5449 - val_acc: 0.8589\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2746 - acc: 0.9042 - val_loss: 0.6810 - val_acc: 0.8248\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2736 - acc: 0.9038 - val_loss: 0.6991 - val_acc: 0.8316\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2734 - acc: 0.9044 - val_loss: 0.6914 - val_acc: 0.8304\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2727 - acc: 0.9043 - val_loss: 0.5920 - val_acc: 0.8468\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2686 - acc: 0.9050 - val_loss: 0.7139 - val_acc: 0.8230\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2668 - acc: 0.9061 - val_loss: 0.6485 - val_acc: 0.8397\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2737 - acc: 0.9047 - val_loss: 0.6288 - val_acc: 0.8401\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2701 - acc: 0.9055 - val_loss: 0.8012 - val_acc: 0.8088\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 126s 3ms/step - loss: 0.2664 - acc: 0.9088 - val_loss: 0.7952 - val_acc: 0.8139\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2669 - acc: 0.9059 - val_loss: 0.7846 - val_acc: 0.8137\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2674 - acc: 0.9064 - val_loss: 0.6907 - val_acc: 0.8228\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2655 - acc: 0.9068 - val_loss: 0.8449 - val_acc: 0.8031\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2631 - acc: 0.9071 - val_loss: 0.8596 - val_acc: 0.8056\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 126s 3ms/step - loss: 0.2694 - acc: 0.9058 - val_loss: 0.6329 - val_acc: 0.8378\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2666 - acc: 0.9069 - val_loss: 0.5416 - val_acc: 0.8601\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2633 - acc: 0.9079 - val_loss: 0.7209 - val_acc: 0.8207\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2643 - acc: 0.9067 - val_loss: 0.6517 - val_acc: 0.8378\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2584 - acc: 0.9096 - val_loss: 0.6159 - val_acc: 0.8397\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2639 - acc: 0.9071 - val_loss: 0.7776 - val_acc: 0.8194\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2591 - acc: 0.9092 - val_loss: 0.6139 - val_acc: 0.8426\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2608 - acc: 0.9095 - val_loss: 0.9958 - val_acc: 0.7787\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2599 - acc: 0.9087 - val_loss: 0.8166 - val_acc: 0.8086\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2594 - acc: 0.9077 - val_loss: 0.6310 - val_acc: 0.8420\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2579 - acc: 0.9089 - val_loss: 0.5888 - val_acc: 0.8502\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2588 - acc: 0.9097 - val_loss: 0.9406 - val_acc: 0.7888\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2559 - acc: 0.9111 - val_loss: 0.5973 - val_acc: 0.8484\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.2589 - acc: 0.9098 - val_loss: 0.7844 - val_acc: 0.8146\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2580 - acc: 0.9096 - val_loss: 0.6877 - val_acc: 0.8374\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 0.2522 - acc: 0.9113 - val_loss: 0.6046 - val_acc: 0.8498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1f312b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e42e8b71-763c-4080-d3c2-38b20530dc52"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 14s 1ms/step\n",
            "Test loss: 0.6045607993364334\n",
            "Test accuracy: 0.8498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2098eda-f67d-4bcc-d9ce-66cc34b22790"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}